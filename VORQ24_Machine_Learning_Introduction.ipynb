{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJDlAPPznjD28FEv3GAsp+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgoldschmid/VORQ23-Intro-To-ML/blob/main/VORQ23_Machine_Learning_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Einführung in Machine Learning mit Python\n",
        "\n",
        "## Beispiel: Erkennung der Schwertlilien-Art (Iris) anhand von Messdaten\n",
        "\n",
        "Eines der bekanntesten Datasets für ML ist das Iris-Dataset (https://archive.ics.uci.edu/dataset/53/iris)\n",
        "\n",
        "Dafür wurden verschiedene Gattungen von Schwertlilien auf ihre Blütenblatt- und Kelchblatt-Länge untersucht (petal/sepal length).\n",
        "\n",
        "Folgende Gattungen wurden untersucht:\n",
        "* Iris Setosa\n",
        "* Iris Versicolour\n",
        "* Iris Virginica\n",
        "\n",
        "### Verständnis für das Dataset\n",
        "\n",
        "Es ist immer wichtig zu wissen, mit welchen Daten gearbeitet wird. Hier sehen wir visualisiert, mit was wir es zu tun haben:\n",
        "\n",
        "![Iris](https://www.embedded-robotics.com/wp-content/uploads/2022/01/Iris-Dataset-Classification-1024x367.png)\n",
        "\n",
        "## Aufgabe\n",
        "\n",
        "Anhand der Messdaten wollen wir ein Model trainieren, das die Gattung automatisch erkennen kann, wenn die entsprechenden Blattlängen gegeben sind.\n",
        "\n",
        "### **Lasst uns anfangen!**"
      ],
      "metadata": {
        "id": "saDNc60ZBKzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importe Verwalten\n",
        "\n",
        "In unserem Notebook können wir Code-Abschnitte strukturieren. Zu beginn erstellen wir einen Abschnitt, um die Importe zu verwalten. Python bietet zwar viel Funktionalität, jedoch benötigen wir noch weitere Libraries um unsere Aufgabe zu erfüllen.\n",
        "\n"
      ],
      "metadata": {
        "id": "dSlNQfN7HXfp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "W-PiMeA9-DO3"
      },
      "outputs": [],
      "source": [
        "# Managing all necessary libraries/imports\n",
        "\n",
        "# Libraries that we are going to need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Task 01: Import datasets\n",
        "\n",
        "\n",
        "# Task 03: Import train_test_split\n",
        "\n",
        "\n",
        "# Task 05: Import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# Task 07: Import confusion_matrix and accuracy_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Das Datenset laden\n",
        "\n",
        "Zuerst müssen wir uns das Datenset holen. Glücklicherweise existiert eine Library, welche das Datenset integriert hat.\n",
        "\n",
        "### Scikit Learn (https://scikit-learn.org/stable/)\n",
        "\n",
        "Scikit Learn ist eine Open Source Machine Learning Library für Python. Sie enthält eine große Anzahl an bereits implementierten Algorithmen und Funktionalitäten, die wir uns nutze machen können.\n",
        "\n",
        "---\n",
        "\n",
        "### **Task 01**\n",
        "\n",
        "Importiert \"datasets\" von der Scikit-Learn Library (kurz \"sklearn\") im Code-Abschnitt zuvor.\n",
        "\n",
        "*Python Tipp:*\n",
        "```\n",
        "# Syntax for importing a library with python\n",
        "from x import y\n",
        "```\n",
        "\n",
        "Details zum Dataset: https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-plants-dataset\n",
        "\n",
        "---\n",
        "\n",
        "### **Task 02**\n",
        "\n",
        "Speichere das Dataset in einer Variable 'iris'.\n",
        "\n",
        "*Python Tipp:*\n",
        "```\n",
        "# Syntax for creating a variable\n",
        "variable = \"This is a string\"\n",
        "number = 10\n",
        "```\n",
        "\n",
        "Dokumentation: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris"
      ],
      "metadata": {
        "id": "73N5HcGtHyTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 02: Load iris dataset from sklearn\n"
      ],
      "metadata": {
        "id": "tQno-0x8-Gsm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Überprüfung\n",
        "\n",
        "Wenn alles geklappt hat, sollte der folgende Code-Abschnitt korrekt ausgeführt werden. Das Dataset wird in ein neues Objekt umgewandelt (nicht so wichtig fürs erste) und anschließend werden die ersten 5 Zeilen der Tabelle ausgegeben."
      ],
      "metadata": {
        "id": "SXMN9BJ7MIrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the dataset to a pandas DataFrame\n",
        "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris['feature_names'] + ['target'])\n",
        "\n",
        "# Display the first five rows of the DataFrame\n",
        "print(iris_df.head())"
      ],
      "metadata": {
        "id": "oaaR-JipMHcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sets erstellen\n",
        "\n",
        "Als nächstes erstellen wir uns ein \"Feature-Set\" (X) und ein \"Target-Set\" (y).\n",
        "\n",
        "Im Grund sind das zwei Arrays. Das eine (X) enthält die Daten der Schwertlilien, die sog. Features die meist \"X\" benannt werden. Das andere (y) enthält die zugehörigen \"Targets\", also das Label der Gattung, welche zu den Maßen der jeweiligen Zeile gehört. Dieses Array aus Labels wird meist mit \"y\" benannt."
      ],
      "metadata": {
        "id": "cseAYdHvM1dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only sepal length and width as the feature set (X) \n",
        "# Select the target species as the target set (y)\n",
        "X = iris_df.iloc[:, :2].values\n",
        "y = iris_df.iloc[:, -1].values\n",
        "print(\"Unique Targets:\")\n",
        "print(np.unique(y))\n"
      ],
      "metadata": {
        "id": "DFkexz7r-H2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training- und Test-Set erstellen\n",
        "\n",
        "Im nächsten Schritt müssen wir unser Dataset in ein Training-Set und ein Test-Set unterteilen. Mithilfe des Training-Sets werden wir unser Model trainieren. Das heißt, dass das Model aus diesem Set seine Muster erkennt und lernt. Mithilfe des Test-Sets überprüfen wir im Anschluss, wie gut das Model funktioniert. Das Model soll die Daten aus dem Test-Set nicht kennen, um eine unabhängige Übprüfung machen zu können.\n",
        "\n",
        "Üblicherweise werden 80% der vorhandenen Daten in das Training-Set gesteckt, die übrigen 20% werden für das Test-Set verwendet.\n",
        "\n",
        "Um die Sets zu erstellen, nutzen wir die Funktion *train_test_split* aus der Scikit-Learn library. \n",
        "\n",
        "---\n",
        "\n",
        "### **Task 03**\n",
        "\n",
        "Importiert *train_test_split* im ersten Code-Abschnitt.\n",
        "\n",
        "Versucht über die Dokumentation selbst herauszufinden, wie der Import funktioniert.\n",
        "\n",
        "Dokumentation *train_test_split*:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Task 04**\n",
        "\n",
        "Erstellt 4 Variablen für die Trainings- und Test-Sets zu den Features (X) und den Targets (y).\n",
        "\n",
        "Die Variablen müssen folgende Namen haben:\n",
        "\n",
        "1.   X_train\n",
        "2.   X_test\n",
        "3.   y_train\n",
        "4.   y_test\n",
        "\n",
        "\n",
        "*Python Tipp:*\n",
        "```\n",
        "# Syntax for creating multiple variables at once\n",
        "a, b, c = ...\n",
        "```\n",
        "\n",
        "Die Variablen sollen über die Funktion *train_test_split* befüllt werden. Über die Dokumentation (siehe oben) findet ihr die korrekte Anwendungsweise.\n",
        "\n",
        "**Beachtet**: Setzt die Größe des Test-Sets auf 20% (0.2) und den random_state auf 1!"
      ],
      "metadata": {
        "id": "3g5PTd-tNpLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 04: Split the dataset into training set and test set\n"
      ],
      "metadata": {
        "id": "iMUqh9RM-KQn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifier erstellen\n",
        "\n",
        "Der K-Nearest Neighbors Algorithmus ist bereits in der Library implementiert. Um ihn zu nutzen müssen wir *KNeighborsClassifier* importieren.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Task 05**\n",
        "\n",
        "Importiert den KNN Classifier im ersten Code-Abschnitt.\n",
        "\n",
        "Versucht wieder über die Dokumentation selbst herauszufinden, wie der Import funktioniert.\n",
        "\n",
        "Dokumentation: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Task 06**\n",
        "\n",
        "Erstelllt den Classifier und nehmt 3 für das \"k\" (*n_neighbors*). Nutzt auch die Dokumentation (siehe oben)."
      ],
      "metadata": {
        "id": "BOtke1KaQ4pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 06: Creating the KNN Classifier\n"
      ],
      "metadata": {
        "id": "ICtZq4d--Lwy"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Das Model trainieren\n",
        "\n",
        "Nachdem wir den Classifier erstellt haben, können wir das Model trainieren.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Task 07**\n",
        "\n",
        "Für das Training können wir die *.fit()* Methode nutzen. Als Parameter müssen wir die beiden Training-Sets übergeben.\n",
        "\n",
        "Dokumentation (*.fit()*): https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.fit"
      ],
      "metadata": {
        "id": "maCVUuhfRp8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 07: Train the model using the training datasets\n"
      ],
      "metadata": {
        "id": "WJ2ha4ZGRqDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy überprüfen\n",
        "\n",
        "Nachdem das Model trainiert wurde, können wir mithilfe des Test-Sets eine sog. \"prediction\" machen. Wir testen also das Model auf seine genauigkeit.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Task 08**\n",
        "\n",
        "Für den Test der Genauigkeit und anschließender Visualisierung müssen wir noch zwei letzte Methoden importieren: *confusion_matrix* und *accuracy_score* aus dem *metrics*-Modul der Scikit-Learn Library.\n",
        "\n",
        "Versucht wieder über die Dokumentation selbst herauszufinden, wie der Import funktioniert.\n",
        "\n",
        "Dokumentation (*metrics*): https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
        "\n",
        "Dokumentation (*confusion_matrix*): https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "\n",
        "Dokumentation (*accuracy_score*): https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Task 09**\n",
        "\n",
        "Führt die *.predict()* Methode des Classifiers (*knn*) aus und übergebt als Parameter unser Test-Set (Achtung, nur das Test-Set mit den Features, also *X*).\n",
        "\n",
        "Speichert das Ergebnis in einer Variable *y_pred*.\n",
        "\n",
        "Dokumentation (*.predict()*): https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict"
      ],
      "metadata": {
        "id": "TswVc7IoToHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 09: Predict the class for the test dataset\n"
      ],
      "metadata": {
        "id": "yONLvfe3-O79"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Task 10**\n",
        "\n",
        "Gebt nun die Genauigkeit mithilfe der *accuracy_score*-Methode aus (Dokumentation siehe oben). Als Parameter benötigen wir die Targets aus dem Test-Set und die gespeicherten Werte unserer Prediction.\n",
        "\n",
        "*Python Tipp:*\n",
        "```\n",
        "# Syntax for printing strings/variables:\n",
        "print(\"Returnvalue of some function:\", function(x, y))\n",
        "```"
      ],
      "metadata": {
        "id": "7JetarIchDv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 10: Model Accuracy\n"
      ],
      "metadata": {
        "id": "OZgswvZthC9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Task 11**\n",
        "\n",
        "Ruft nun die Funktion *confusion_matrix()* auf, um eine Confusion Matrix zu erzeugen. Mit ihrer Hilfe können wir sehen, wie unser Model im Detail abgeschnitten hat. Als Parameter benötigen wir wieder die Targets aus dem Test-Set und die gespeicherten Werte unserer Prediction.\n",
        "\n",
        "Das Ergebnis speichern wir in einer Variable *cm*."
      ],
      "metadata": {
        "id": "jaOjXyKph2y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 11: Create the confusion matrix\n",
        "\n",
        "\n",
        "# Print the matrix\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "UvwXNu27-P_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visuelle Einsicht in unser Model\n",
        "\n",
        "Nun können wir uns noch ansehen, wie der Algorithmus gearbeitet hat. Damit bekommen wir ein Verständnis darüber, wie unser Model funktioniert und wo wir eventuell noch etwas verbessern können.\n",
        "\n",
        "### Visualisierung der Features unseres Datensets\n",
        "\n",
        "Bevor wir unser Model ansehen, schauen wir uns einmal das Datenset genauer an. In nachfolgendem Plot sehen wir die verschiedenen Blumen und ihre Sepal Breite bzw. Höhe. "
      ],
      "metadata": {
        "id": "Obqtas9UiwVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "plt.scatter(iris_df.iloc[:, 0], iris_df.iloc[:, 1], c=iris.target)\n",
        "plt.xlabel('Sepal Length cm')\n",
        "plt.ylabel('Sepal Width cm')\n",
        "plt.title('Iris dataset Sepal dimensions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qEIyrWce-Tlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisierung des Models\n",
        "\n",
        "Nun sehen wir uns an, wie unser Model die Grenzen gesetzt hat:"
      ],
      "metadata": {
        "id": "ttYtsd-uTyFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h = .02\n",
        "cmap_light = ListedColormap(['#3D0752', '#4D8E8C', '#F7E846'])\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure()\n",
        "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)"
      ],
      "metadata": {
        "id": "pZbBzKgYCvhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeit zu experimentieren!\n",
        "\n",
        "Nun könnt ihr euch austoben. Der erste Schritt, wäre den \"k\"-Wert unseres Algorithmus anzupassen, und zu sehen, wie sich die Genauigkeit verändert. Erstellt dann auch den letzten Plot neu, uns seht euch an, wie sich die Grenzen verändert haben!\n",
        "\n",
        "### Ausblick\n",
        "\n",
        "Wenn ihr euch weiter damit beschäftigen wollt, nehmt alle Werte des Datasets in den Algorithmus mit hinein, und seht euch an, wie sich die Genauigkeit verändert. Dazu müsst ihr die Aufbereitung der Daten anpassen. Lasst euch aber nicht entmutigen, wenn ihr euch mit Python oder ML allgemein noch schwer tut! :-)\n",
        "\n",
        "**Alles Gute!**"
      ],
      "metadata": {
        "id": "wO673hvakfbg"
      }
    }
  ]
}
